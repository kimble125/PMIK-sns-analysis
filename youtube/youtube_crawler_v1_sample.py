#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
YouTube PMIK íŒë§¤ì› ë°ì´í„° ìˆ˜ì§‘ê¸° v1.0 (ìƒ˜í”Œ ì½”ë“œ)

ê¸°ëŠ¥:
1. YouTube Data API v3ë¡œ ì˜ìƒ ê²€ìƒ‰
2. ì˜ìƒ ë©”íƒ€ë°ì´í„° ìˆ˜ì§‘
3. í•„í„°ë§ (ë„¤ì´ë²„ ë¸”ë¡œê·¸ ë¡œì§ ì¬ì‚¬ìš©)
4. CSV ì €ì¥

ì°¸ê³ :
- pm_naver_blog_crawler_v8_4_final.py êµ¬ì¡° ì°¸ê³ 
- í•„í„°ë§ ë¡œì§ ì¬ì‚¬ìš©
"""

import os
import json
import time
import logging
from datetime import datetime
from typing import List, Dict, Optional
import re
from pathlib import Path

import pandas as pd
from googleapiclient.discovery import build
from googleapiclient.errors import HttpError
from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ
env_path = Path(__file__).parent / '.env'
load_dotenv(dotenv_path=env_path)

# ===========================
# ë¡œê¹… ì„¤ì •
# ===========================
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)

# ===========================
# ì„¤ì •ê°’
# ===========================

# YouTube API í‚¤ (í™˜ê²½ë³€ìˆ˜ ë˜ëŠ” config.pyì—ì„œ ë¡œë“œ)
try:
    import config
    YOUTUBE_API_KEY = config.YOUTUBE_API_KEY
except ImportError:
    YOUTUBE_API_KEY = os.getenv('YOUTUBE_API_KEY', '')

if not YOUTUBE_API_KEY:
    logger.error("âŒ YouTube API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    logger.error("   .env íŒŒì¼ì— YOUTUBE_API_KEYë¥¼ ì¶”ê°€í•˜ê±°ë‚˜")
    logger.error("   config.pyì— YOUTUBE_API_KEYë¥¼ ì„¤ì •í•˜ì„¸ìš”.")
    exit(1)

# ê²€ìƒ‰ í‚¤ì›Œë“œ (ë„¤ì´ë²„ ë¸”ë¡œê·¸ì™€ ë™ì¼)
SEARCH_KEYWORDS = [
    "í”¼ì— ì¸í„°ë‚´ì…”ë„",
    "ë…ì¼í”¼ì— ",
    "PMì¸í„°ë‚´ì…”ë„",
    "í”¼íŠ¸ë¼ì¸",
    "í”¼ì— ì½”ë¦¬ì•„",
    "íƒ‘ì‰ì´í”„",
    "í”„ë¡œì‰ì´í”„",
]

# í•„í„°ë§ í‚¤ì›Œë“œ (ë„¤ì´ë²„ ë¸”ë¡œê·¸ì—ì„œ ì¬ì‚¬ìš©)
PM_BRAND_KEYWORDS = [
    "í”¼ì— ", "í”¼ì— ì¸í„°ë‚´ì…”ë„", "PM International", "PMInternational",
    "PM", "FitLine", "í•ë¼ì¸", "í”¼íŠ¸ë¼ì¸"
]

PM_SALES_KEYWORDS = [
    "ì¶”ì²œì¸", "ì¶”ì²œì¸ì½”ë“œ", "ì¶”ì²œì¸ ì½”ë“œ", "ì¶”ì²œì¸ë²ˆí˜¸", "ì¶”ì²œì¸ ë²ˆí˜¸",
    "íŒŒíŠ¸ë„ˆ", "íŒŒíŠ¸ë„ˆì½”ë“œ", "íŒŒíŠ¸ë„ˆ ì½”ë“œ", "íŒŒíŠ¸ë„ˆë²ˆí˜¸", "íŒŒíŠ¸ë„ˆ ë²ˆí˜¸",
    "ë“±ë¡", "ê°€ì…", "ë¬¸ì˜"
]

EXCLUDE_KEYWORDS = [
    "ë‰´ìŠ¤", "ê¸°ì‚¬", "ë³´ë„", "ê³µì§€", "ì±„ìš©", "êµ¬ì¸", "êµ¬ì§",
    "ë§¤íŠ¸ë¦¬ìŠ¤", "ì¹¨ëŒ€", "ì£¼ê°€", "ì£¼ì‹", "ìƒì¥"
]

MAX_RESULTS_PER_KEYWORD = 50  # í‚¤ì›Œë“œë‹¹ ìµœëŒ€ ê²°ê³¼ ìˆ˜
TOTAL_TARGET = 1000  # ëª©í‘œ ìˆ˜ì§‘ ê°œìˆ˜

# ===========================
# YouTube API í´ë¼ì´ì–¸íŠ¸
# ===========================

def get_youtube_client():
    """YouTube API í´ë¼ì´ì–¸íŠ¸ ìƒì„±"""
    return build('youtube', 'v3', developerKey=YOUTUBE_API_KEY)

# ===========================
# ì¶”ì²œì¸ ì •ë³´ ì¶”ì¶œ (ë„¤ì´ë²„ ë¸”ë¡œê·¸ ì¬ì‚¬ìš©)
# ===========================

def extract_sponsor_phone(text: str) -> str:
    """ì¶”ì²œì¸ ì „í™”ë²ˆí˜¸ ì¶”ì¶œ"""
    if not text:
        return ""
    
    phone_patterns = [
        r'010[-\s]?\d{4}[-\s]?\d{4}',
        r'ì¶”ì²œì¸.*?010[-\s]?\d{4}[-\s]?\d{4}',
        r'ë¬¸ì˜.*?010[-\s]?\d{4}[-\s]?\d{4}',
    ]
    
    for pattern in phone_patterns:
        match = re.search(pattern, text)
        if match:
            phone = match.group(0)
            digits = re.sub(r'\D', '', phone)
            if digits.startswith('010') and len(digits) == 11:
                return f"{digits[:3]}-{digits[3:7]}-{digits[7:]}"
    
    return ""

def extract_sponsor_partner_id(text: str) -> str:
    """ì¶”ì²œì¸ íŒŒíŠ¸ë„ˆ ID ì¶”ì¶œ (ì •í™•íˆ 8ìë¦¬)"""
    if not text:
        return ""
    
    partner_patterns = [
        r'ì¶”ì²œì¸\s*(?:ì½”ë“œ|ë²ˆí˜¸|ID)?\s*[:ï¼š]?\s*(\d{8})\b',
        r'íŒŒíŠ¸ë„ˆ\s*(?:ì½”ë“œ|ë²ˆí˜¸|ID)?\s*[:ï¼š]?\s*(\d{8})\b',
        r'\b(\d{8})\b',
    ]
    
    for pattern in partner_patterns:
        matches = re.findall(pattern, text)
        for match in matches:
            if len(match) == 8:
                return match
    
    return ""

def extract_hashtags(text: str) -> str:
    """í•´ì‹œíƒœê·¸ ì¶”ì¶œ"""
    if not text:
        return ""
    
    hashtag_pattern = r'#([ê°€-í£a-zA-Z0-9_]+)'
    matches = re.findall(hashtag_pattern, text)
    
    if matches:
        return ', '.join([f'#{tag}' for tag in matches])
    return ""

# ===========================
# í•„í„°ë§ í•¨ìˆ˜ (ë„¤ì´ë²„ ë¸”ë¡œê·¸ ì¬ì‚¬ìš©)
# ===========================

def content_passes_filter(title: str, description: str) -> tuple[bool, str]:
    """
    ì½˜í…ì¸  í•„í„°ë§
    
    Returns:
        (í†µê³¼ì—¬ë¶€, ì‹¤íŒ¨ì‚¬ìœ )
    """
    full_text = f"{title} {description}".lower()
    
    # 1. ì œì™¸ í‚¤ì›Œë“œ ì²´í¬
    exclude_count = sum(1 for keyword in EXCLUDE_KEYWORDS if keyword in full_text)
    if exclude_count >= 2:
        return False, f"ì œì™¸ í‚¤ì›Œë“œ {exclude_count}ê°œ ë°œê²¬"
    
    # 2. PM ë¸Œëœë“œ í‚¤ì›Œë“œ ì²´í¬
    has_pm_keyword = any(keyword.lower() in full_text for keyword in PM_BRAND_KEYWORDS)
    if not has_pm_keyword:
        return False, "PM ë¸Œëœë“œ í‚¤ì›Œë“œ ì—†ìŒ"
    
    return True, ""

# ===========================
# YouTube ê²€ìƒ‰ ë° ìˆ˜ì§‘
# ===========================

def search_youtube_videos(youtube, keyword: str, max_results: int = 50) -> List[str]:
    """
    YouTubeì—ì„œ í‚¤ì›Œë“œë¡œ ì˜ìƒ ê²€ìƒ‰
    
    Returns:
        video_id ë¦¬ìŠ¤íŠ¸
    """
    try:
        logger.info(f"ğŸ” ê²€ìƒ‰ ì¤‘: '{keyword}'")
        
        request = youtube.search().list(
            q=keyword,
            type='video',
            part='id',
            maxResults=max_results,
            order='relevance',  # ê´€ë ¨ë„ìˆœ
            regionCode='KR',  # í•œêµ­ ì§€ì—­
            relevanceLanguage='ko',  # í•œêµ­ì–´
        )
        
        response = request.execute()
        
        video_ids = [item['id']['videoId'] for item in response.get('items', [])]
        logger.info(f"   âœ… {len(video_ids)}ê°œ ì˜ìƒ ë°œê²¬")
        
        return video_ids
    
    except HttpError as e:
        logger.error(f"   âŒ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        return []

def get_video_details(youtube, video_ids: List[str]) -> List[Dict]:
    """
    ì˜ìƒ ìƒì„¸ ì •ë³´ ì¡°íšŒ
    
    Returns:
        ì˜ìƒ ì •ë³´ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸
    """
    if not video_ids:
        return []
    
    try:
        # ìµœëŒ€ 50ê°œì”© ë°°ì¹˜ ì²˜ë¦¬
        video_data = []
        
        for i in range(0, len(video_ids), 50):
            batch_ids = video_ids[i:i+50]
            
            request = youtube.videos().list(
                id=','.join(batch_ids),
                part='snippet,statistics,contentDetails'
            )
            
            response = request.execute()
            
            for item in response.get('items', []):
                snippet = item['snippet']
                statistics = item.get('statistics', {})
                content_details = item['contentDetails']
                
                # ë°ì´í„° ì¶”ì¶œ
                video_info = {
                    'platform': 'youtube',
                    'video_id': item['id'],
                    'url': f"https://www.youtube.com/watch?v={item['id']}",
                    'channel_id': snippet['channelId'],
                    'channel_name': snippet['channelTitle'],
                    'title': snippet['title'],
                    'description': snippet.get('description', ''),
                    'published_datetime': snippet['publishedAt'],
                    'duration': content_details['duration'],
                    'view_count': int(statistics.get('viewCount', 0)),
                    'like_count': int(statistics.get('likeCount', 0)),
                    'comment_count': int(statistics.get('commentCount', 0)),
                    'favorite_count': int(statistics.get('favoriteCount', 0)),
                    'category_id': snippet.get('categoryId', ''),
                    'tags': ', '.join(snippet.get('tags', [])),
                    'thumbnail_url': snippet['thumbnails'].get('maxres', snippet['thumbnails']['high'])['url'],
                    'collected_date': datetime.now().strftime('%Y-%m-%d'),
                }
                
                # ì¶”ì²œì¸ ì •ë³´ ì¶”ì¶œ
                full_text = f"{video_info['title']} {video_info['description']}"
                video_info['sponsor_phone'] = extract_sponsor_phone(full_text)
                video_info['sponsor_partner_id'] = extract_sponsor_partner_id(full_text)
                video_info['hashtags'] = extract_hashtags(video_info['description'])
                
                video_data.append(video_info)
        
        return video_data
    
    except HttpError as e:
        logger.error(f"âŒ ì˜ìƒ ìƒì„¸ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return []

def get_channel_statistics(youtube, channel_id: str) -> Dict:
    """ì±„ë„ í†µê³„ ì¡°íšŒ"""
    try:
        request = youtube.channels().list(
            id=channel_id,
            part='statistics'
        )
        
        response = request.execute()
        
        if response.get('items'):
            stats = response['items'][0]['statistics']
            return {
                'channel_subscriber_count': int(stats.get('subscriberCount', 0)),
                'channel_video_count': int(stats.get('videoCount', 0)),
                'channel_view_count': int(stats.get('viewCount', 0)),
            }
    
    except HttpError as e:
        logger.error(f"âŒ ì±„ë„ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
    
    return {
        'channel_subscriber_count': 0,
        'channel_video_count': 0,
        'channel_view_count': 0,
    }

# ===========================
# ë©”ì¸ í¬ë¡¤ë§ í•¨ìˆ˜
# ===========================

def main():
    """ë©”ì¸ í¬ë¡¤ë§ í•¨ìˆ˜"""
    logger.info("=" * 70)
    logger.info("ğŸ¬ YouTube PMIK íŒë§¤ì› ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘")
    logger.info("=" * 70)
    
    # YouTube API í´ë¼ì´ì–¸íŠ¸
    youtube = get_youtube_client()
    
    # ìˆ˜ì§‘ ë°ì´í„°
    all_videos = []
    seen_video_ids = set()
    
    # í‚¤ì›Œë“œë³„ ê²€ìƒ‰
    for keyword in SEARCH_KEYWORDS:
        logger.info(f"\n{'='*70}")
        logger.info(f"ğŸ” í‚¤ì›Œë“œ: {keyword}")
        logger.info(f"{'='*70}")
        
        # ê²€ìƒ‰
        video_ids = search_youtube_videos(youtube, keyword, MAX_RESULTS_PER_KEYWORD)
        
        # ì¤‘ë³µ ì œê±°
        new_video_ids = [vid for vid in video_ids if vid not in seen_video_ids]
        logger.info(f"   ğŸ’¡ ìƒˆë¡œìš´ ì˜ìƒ: {len(new_video_ids)}ê°œ")
        
        if not new_video_ids:
            continue
        
        # ìƒì„¸ ì •ë³´ ì¡°íšŒ
        logger.info(f"   ğŸ“¥ ìƒì„¸ ì •ë³´ ì¡°íšŒ ì¤‘...")
        video_details = get_video_details(youtube, new_video_ids)
        
        # í•„í„°ë§
        filtered_count = 0
        for video in video_details:
            # ì¤‘ë³µ ì²´í¬
            if video['video_id'] in seen_video_ids:
                continue
            
            # í•„í„°ë§
            passes, reason = content_passes_filter(video['title'], video['description'])
            if not passes:
                filtered_count += 1
                logger.debug(f"   ğŸ” í•„í„°ë§: {video['title'][:30]}... ({reason})")
                continue
            
            # ì±„ë„ í†µê³„ ì¶”ê°€
            channel_stats = get_channel_statistics(youtube, video['channel_id'])
            video.update(channel_stats)
            
            all_videos.append(video)
            seen_video_ids.add(video['video_id'])
        
        logger.info(f"   âœ… ìˆ˜ì§‘: {len(video_details) - filtered_count}ê°œ")
        logger.info(f"   ğŸ” í•„í„°ë§: {filtered_count}ê°œ")
        logger.info(f"   ğŸ“Š ì´ ìˆ˜ì§‘: {len(all_videos)}ê°œ")
        
        # ëª©í‘œ ë‹¬ì„± ì‹œ ì¢…ë£Œ
        if len(all_videos) >= TOTAL_TARGET:
            logger.info(f"\nğŸ‰ ëª©í‘œ ë‹¬ì„±! ({len(all_videos)}ê°œ ìˆ˜ì§‘)")
            break
        
        # API í• ë‹¹ëŸ‰ ë³´í˜¸ (Rate limiting)
        time.sleep(1)
    
    # ===========================
    # CSV ì €ì¥
    # ===========================
    
    if not all_videos:
        logger.warning("âš ï¸  ìˆ˜ì§‘ëœ ì˜ìƒì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    logger.info(f"\n{'='*70}")
    logger.info("ğŸ’¾ CSV ì €ì¥ ì¤‘...")
    logger.info(f"{'='*70}")
    
    df = pd.DataFrame(all_videos)
    
    # ì»¬ëŸ¼ ìˆœì„œ ì •ë ¬
    column_order = [
        'platform', 'video_id', 'url',
        'channel_id', 'channel_name', 'channel_subscriber_count', 
        'channel_video_count', 'channel_view_count',
        'title', 'description', 'published_datetime',
        'duration', 'view_count', 'like_count', 'comment_count', 
        'favorite_count', 'category_id',
        'tags', 'hashtags',
        'sponsor_phone', 'sponsor_partner_id',
        'thumbnail_url', 'collected_date'
    ]
    
    df = df[column_order]
    
    # íŒŒì¼ëª… ìƒì„±
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    output_file = f'youtube_pm_v1_{timestamp}.csv'
    
    df.to_csv(output_file, index=False, encoding='utf-8-sig')
    logger.info(f"âœ… ì €ì¥ ì™„ë£Œ: {output_file}")
    logger.info(f"   ì´ {len(df)}ê°œ ì˜ìƒ")
    
    # ===========================
    # í†µê³„ ì¶œë ¥
    # ===========================
    
    logger.info(f"\n{'='*70}")
    logger.info("ğŸ“Š ìˆ˜ì§‘ í†µê³„")
    logger.info(f"{'='*70}")
    logger.info(f"ì´ ì˜ìƒ ìˆ˜: {len(df)}")
    logger.info(f"ì¶”ì²œì¸ ì „í™”ë²ˆí˜¸ í¬í•¨: {df['sponsor_phone'].notna().sum()}ê°œ")
    logger.info(f"íŒŒíŠ¸ë„ˆ ID í¬í•¨: {df['sponsor_partner_id'].notna().sum()}ê°œ")
    logger.info(f"í‰ê·  ì¡°íšŒìˆ˜: {df['view_count'].mean():.0f}")
    logger.info(f"í‰ê·  ì¢‹ì•„ìš”: {df['like_count'].mean():.0f}")
    logger.info(f"í‰ê·  ëŒ“ê¸€: {df['comment_count'].mean():.0f}")
    
    # ìƒìœ„ ì±„ë„
    logger.info(f"\nğŸ“º ìƒìœ„ ì±„ë„ (êµ¬ë…ììˆœ):")
    top_channels = df.groupby(['channel_name', 'channel_subscriber_count']).size().reset_index(name='ì˜ìƒìˆ˜')
    top_channels = top_channels.sort_values('channel_subscriber_count', ascending=False).head(5)
    for _, row in top_channels.iterrows():
        logger.info(f"   - {row['channel_name']}: êµ¬ë…ì {row['channel_subscriber_count']:,}ëª…, ì˜ìƒ {row['ì˜ìƒìˆ˜']}ê°œ")
    
    logger.info(f"\n{'='*70}")
    logger.info("âœ… ìˆ˜ì§‘ ì™„ë£Œ!")
    logger.info(f"{'='*70}")
    logger.info(f"\nğŸ“ ë‹¤ìŒ ë‹¨ê³„:")
    logger.info(f"   1. youtube_transcript_collector.pyë¡œ ìë§‰ ìˆ˜ì§‘")
    logger.info(f"   2. Google Colabì—ì„œ ì¸ë„¤ì¼ OCR")
    logger.info(f"   3. merge_youtube_analysis.pyë¡œ ê²°ê³¼ ë³‘í•©")

if __name__ == "__main__":
    main()
