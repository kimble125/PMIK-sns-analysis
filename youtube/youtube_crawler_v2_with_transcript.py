#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
YouTube PMIK íŒë§¤ì› ë°ì´í„° ìˆ˜ì§‘ê¸° v2.0 (ìë§‰ í¬í•¨)

v2.0 ì‹ ê·œ ê¸°ëŠ¥:
1. YouTube ê³µì‹ ìë§‰ ìˆ˜ì§‘ (youtube-transcript-api)
2. ìë§‰ ì—†ëŠ” ì˜ìƒ í‘œì‹œ (Whisper ëŒ€ê¸°ì—´)
3. 300ê°œ ì´ìƒ ëŒ€ëŸ‰ ìˆ˜ì§‘ ìµœì í™”
4. ì§„í–‰ë¥  í‘œì‹œ

ì˜ˆìƒ ì‹œê°„:
- 300ê°œ ì˜ìƒ: ì•½ 5-8ë¶„
- 500ê°œ ì˜ìƒ: ì•½ 8-12ë¶„
"""

import os
import json
import time
import logging
from datetime import datetime
from typing import List, Dict, Optional
import re
from pathlib import Path

import pandas as pd
from googleapiclient.discovery import build
from googleapiclient.errors import HttpError
from dotenv import load_dotenv
from youtube_transcript_api import YouTubeTranscriptApi
from youtube_transcript_api._errors import TranscriptsDisabled, NoTranscriptFound

# .env íŒŒì¼ ë¡œë“œ
env_path = Path(__file__).parent / '.env'
load_dotenv(dotenv_path=env_path)

# ===========================
# ë¡œê¹… ì„¤ì •
# ===========================
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)

# ===========================
# ì„¤ì •ê°’ (ëŒ€ëŸ‰ ìˆ˜ì§‘ìš©)
# ===========================

# YouTube API í‚¤
YOUTUBE_API_KEY = os.getenv('YOUTUBE_API_KEY', '')

if not YOUTUBE_API_KEY:
    logger.error("=" * 70)
    logger.error("âŒ YouTube API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
    logger.error("=" * 70)
    logger.error("\n.env íŒŒì¼ì— YOUTUBE_API_KEYë¥¼ ì„¤ì •í•˜ì„¸ìš”.")
    exit(1)

# ê²€ìƒ‰ í‚¤ì›Œë“œ (v2: í™•ì¥)
SEARCH_KEYWORDS = [
    # ì£¼ìš” í‚¤ì›Œë“œ
    "í”¼ì— ì¸í„°ë‚´ì…”ë„",
    "ë…ì¼í”¼ì— ",
    "PMì¸í„°ë‚´ì…”ë„",
    "í”¼íŠ¸ë¼ì¸",
    "í”¼ì— ì½”ë¦¬ì•„",
    # ì œí’ˆ í‚¤ì›Œë“œ
    "íƒ‘ì‰ì´í”„",
    "í”„ë¡œì‰ì´í”„",
    "ë””ë“œë§í¬",
    "ë®¤ë…¸ê²",
    "ì—‘í‹°ë°”ì´ì¦ˆ",
    "íŒŒì›Œì¹µí…Œì¼",
    "ë¦¬ìŠ¤í† ë ˆì´íŠ¸",
]

MAX_RESULTS_PER_KEYWORD = 30  # í‚¤ì›Œë“œë‹¹ 30ê°œ (ì´ 360ê°œ ëª©í‘œ)
TARGET_TOTAL = 300  # ëª©í‘œ ìˆ˜ì§‘ ê°œìˆ˜

# ===========================
# ì¶”ì²œì¸ ì •ë³´ ì¶”ì¶œ
# ===========================

def extract_sponsor_phone(text: str) -> str:
    """ì¶”ì²œì¸ ì „í™”ë²ˆí˜¸ ì¶”ì¶œ"""
    if not text:
        return ""
    
    phone_patterns = [
        r'010[-\s]?\d{4}[-\s]?\d{4}',
    ]
    
    for pattern in phone_patterns:
        match = re.search(pattern, text)
        if match:
            phone = match.group(0)
            digits = re.sub(r'\D', '', phone)
            if digits.startswith('010') and len(digits) == 11:
                return f"{digits[:3]}-{digits[3:7]}-{digits[7:]}"
    
    return ""

def extract_sponsor_partner_id(text: str) -> str:
    """ì¶”ì²œì¸ íŒŒíŠ¸ë„ˆ ID ì¶”ì¶œ (8ìë¦¬)"""
    if not text:
        return ""
    
    partner_patterns = [
        r'ì¶”ì²œì¸\s*(?:ì½”ë“œ|ë²ˆí˜¸|ID)?\s*[:ï¼š]?\s*(\d{8})\b',
        r'íŒŒíŠ¸ë„ˆ\s*(?:ì½”ë“œ|ë²ˆí˜¸|ID)?\s*[:ï¼š]?\s*(\d{8})\b',
        r'\b(\d{8})\b',
    ]
    
    for pattern in partner_patterns:
        matches = re.findall(pattern, text)
        for match in matches:
            if len(match) == 8:
                return match
    
    return ""

def extract_hashtags(text: str) -> str:
    """í•´ì‹œíƒœê·¸ ì¶”ì¶œ"""
    if not text:
        return ""
    
    hashtag_pattern = r'#([ê°€-í£a-zA-Z0-9_]+)'
    matches = re.findall(hashtag_pattern, text)
    
    if matches:
        return ', '.join([f'#{tag}' for tag in matches])
    return ""

# ===========================
# YouTube ìë§‰ ìˆ˜ì§‘
# ===========================

def get_youtube_transcript(video_id: str) -> Dict[str, str]:
    """
    YouTube ìë§‰ ìˆ˜ì§‘
    
    Returns:
        {
            'transcript': ìë§‰ í…ìŠ¤íŠ¸,
            'language': ì–¸ì–´ ì½”ë“œ,
            'status': 'success' | 'no_transcript' | 'error'
        }
    """
    try:
        # í•œêµ­ì–´ ìš°ì„ , ì—†ìœ¼ë©´ ì˜ì–´, ì—†ìœ¼ë©´ ìë™ìƒì„± ìë§‰
        transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)
        
        # 1ìˆœìœ„: í•œêµ­ì–´ ìˆ˜ë™ ìë§‰
        try:
            transcript = transcript_list.find_transcript(['ko'])
            transcript_data = transcript.fetch()
            text = ' '.join([item['text'] for item in transcript_data])
            return {
                'transcript': text,
                'language': 'ko',
                'status': 'success'
            }
        except:
            pass
        
        # 2ìˆœìœ„: í•œêµ­ì–´ ìë™ìƒì„± ìë§‰
        try:
            transcript = transcript_list.find_generated_transcript(['ko'])
            transcript_data = transcript.fetch()
            text = ' '.join([item['text'] for item in transcript_data])
            return {
                'transcript': text,
                'language': 'ko-auto',
                'status': 'success'
            }
        except:
            pass
        
        # 3ìˆœìœ„: ì˜ì–´ ìë§‰
        try:
            transcript = transcript_list.find_transcript(['en'])
            transcript_data = transcript.fetch()
            text = ' '.join([item['text'] for item in transcript_data])
            return {
                'transcript': text,
                'language': 'en',
                'status': 'success'
            }
        except:
            pass
        
        return {
            'transcript': '',
            'language': '',
            'status': 'no_transcript'
        }
    
    except TranscriptsDisabled:
        return {
            'transcript': '',
            'language': '',
            'status': 'disabled'
        }
    except NoTranscriptFound:
        return {
            'transcript': '',
            'language': '',
            'status': 'no_transcript'
        }
    except Exception as e:
        logger.debug(f"ìë§‰ ìˆ˜ì§‘ ì‹¤íŒ¨ ({video_id}): {str(e)}")
        return {
            'transcript': '',
            'language': '',
            'status': 'error'
        }

# ===========================
# YouTube ê²€ìƒ‰ ë° ìˆ˜ì§‘
# ===========================

def get_youtube_client():
    """YouTube API í´ë¼ì´ì–¸íŠ¸ ìƒì„±"""
    return build('youtube', 'v3', developerKey=YOUTUBE_API_KEY)

def search_youtube_videos(youtube, keyword: str, max_results: int = 30) -> List[str]:
    """YouTube ê²€ìƒ‰"""
    try:
        request = youtube.search().list(
            q=keyword,
            type='video',
            part='id',
            maxResults=max_results,
            order='relevance',
            regionCode='KR',
            relevanceLanguage='ko',
        )
        
        response = request.execute()
        video_ids = [item['id']['videoId'] for item in response.get('items', [])]
        
        return video_ids
    
    except HttpError as e:
        logger.error(f"   âŒ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        return []

def get_video_details(youtube, video_ids: List[str]) -> List[Dict]:
    """ì˜ìƒ ìƒì„¸ ì •ë³´ ì¡°íšŒ"""
    if not video_ids:
        return []
    
    try:
        request = youtube.videos().list(
            id=','.join(video_ids),
            part='snippet,statistics,contentDetails'
        )
        
        response = request.execute()
        video_data = []
        
        for item in response.get('items', []):
            snippet = item['snippet']
            statistics = item.get('statistics', {})
            content_details = item['contentDetails']
            
            # ê¸°ë³¸ ì •ë³´
            video_info = {
                'platform': 'youtube',
                'video_id': item['id'],
                'url': f"https://www.youtube.com/watch?v={item['id']}",
                'channel_id': snippet['channelId'],
                'channel_name': snippet['channelTitle'],
                'title': snippet['title'],
                'description': snippet.get('description', ''),
                'published_datetime': snippet['publishedAt'],
                'duration': content_details['duration'],
                'view_count': int(statistics.get('viewCount', 0)),
                'like_count': int(statistics.get('likeCount', 0)),
                'comment_count': int(statistics.get('commentCount', 0)),
                'category_id': snippet.get('categoryId', ''),
                'tags': ', '.join(snippet.get('tags', [])),
                'thumbnail_url': snippet['thumbnails'].get('maxres', snippet['thumbnails']['high'])['url'],
                'collected_date': datetime.now().strftime('%Y-%m-%d'),
            }
            
            # ì¶”ì²œì¸ ì •ë³´ ì¶”ì¶œ
            full_text = f"{video_info['title']} {video_info['description']}"
            video_info['sponsor_phone'] = extract_sponsor_phone(full_text)
            video_info['sponsor_partner_id'] = extract_sponsor_partner_id(full_text)
            video_info['hashtags'] = extract_hashtags(video_info['description'])
            
            video_data.append(video_info)
        
        return video_data
    
    except HttpError as e:
        logger.error(f"âŒ ì˜ìƒ ìƒì„¸ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return []

# ===========================
# ë©”ì¸ í•¨ìˆ˜
# ===========================

def main():
    """ë©”ì¸ í¬ë¡¤ë§ í•¨ìˆ˜"""
    start_time = time.time()
    
    logger.info("=" * 70)
    logger.info("ğŸ¬ YouTube PMIK ë°ì´í„° ìˆ˜ì§‘ê¸° v2.0 (ìë§‰ í¬í•¨)")
    logger.info("=" * 70)
    logger.info(f"í‚¤ì›Œë“œ: {len(SEARCH_KEYWORDS)}ê°œ")
    logger.info(f"í‚¤ì›Œë“œë‹¹ ìˆ˜ì§‘: {MAX_RESULTS_PER_KEYWORD}ê°œ")
    logger.info(f"ëª©í‘œ ìˆ˜ì§‘: {TARGET_TOTAL}ê°œ")
    logger.info(f"ì‹ ê·œ ê¸°ëŠ¥: YouTube ìë§‰ ìë™ ìˆ˜ì§‘")
    logger.info("=" * 70)
    
    # YouTube API í´ë¼ì´ì–¸íŠ¸
    youtube = get_youtube_client()
    
    # ìˆ˜ì§‘ ë°ì´í„°
    all_videos = []
    seen_video_ids = set()
    
    # í†µê³„
    transcript_success = 0
    transcript_failed = 0
    
    # í‚¤ì›Œë“œë³„ ê²€ìƒ‰
    for i, keyword in enumerate(SEARCH_KEYWORDS, 1):
        if len(all_videos) >= TARGET_TOTAL:
            logger.info(f"\nğŸ‰ ëª©í‘œ ë‹¬ì„±! ({len(all_videos)}ê°œ ìˆ˜ì§‘)")
            break
        
        logger.info(f"\n{'='*70}")
        logger.info(f"[{i}/{len(SEARCH_KEYWORDS)}] í‚¤ì›Œë“œ: {keyword}")
        logger.info(f"ì§„í–‰ë¥ : {len(all_videos)}/{TARGET_TOTAL} ({len(all_videos)/TARGET_TOTAL*100:.1f}%)")
        logger.info(f"{'='*70}")
        
        # ê²€ìƒ‰
        logger.info(f"ğŸ” ê²€ìƒ‰ ì¤‘...")
        video_ids = search_youtube_videos(youtube, keyword, MAX_RESULTS_PER_KEYWORD)
        logger.info(f"   âœ… {len(video_ids)}ê°œ ì˜ìƒ ë°œê²¬")
        
        # ì¤‘ë³µ ì œê±°
        new_video_ids = [vid for vid in video_ids if vid not in seen_video_ids]
        
        if not new_video_ids:
            logger.info("   âš ï¸  ìƒˆë¡œìš´ ì˜ìƒ ì—†ìŒ (ì¤‘ë³µ)")
            continue
        
        logger.info(f"   ğŸ’¡ ìƒˆë¡œìš´ ì˜ìƒ: {len(new_video_ids)}ê°œ")
        
        # ìƒì„¸ ì •ë³´ ì¡°íšŒ
        logger.info(f"   ğŸ“¥ ë©”íƒ€ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
        video_details = get_video_details(youtube, new_video_ids)
        logger.info(f"   âœ… ë©”íƒ€ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {len(video_details)}ê°œ")
        
        # ìë§‰ ìˆ˜ì§‘
        logger.info(f"   ğŸ“ ìë§‰ ìˆ˜ì§‘ ì¤‘...")
        for idx, video in enumerate(video_details, 1):
            if video['video_id'] in seen_video_ids:
                continue
            
            # ìë§‰ ìˆ˜ì§‘
            transcript_result = get_youtube_transcript(video['video_id'])
            video['youtube_transcript'] = transcript_result['transcript']
            video['transcript_language'] = transcript_result['language']
            video['transcript_status'] = transcript_result['status']
            video['has_transcript'] = transcript_result['status'] == 'success'
            
            if transcript_result['status'] == 'success':
                transcript_success += 1
            else:
                transcript_failed += 1
            
            # ì§„í–‰ë¥  í‘œì‹œ (10ê°œë§ˆë‹¤)
            if idx % 10 == 0:
                logger.info(f"      ìë§‰ ìˆ˜ì§‘ ì§„í–‰: {idx}/{len(video_details)}")
            
            all_videos.append(video)
            seen_video_ids.add(video['video_id'])
            
            # ëª©í‘œ ë‹¬ì„± ì‹œ ì¢…ë£Œ
            if len(all_videos) >= TARGET_TOTAL:
                break
        
        logger.info(f"   âœ… ìë§‰ ìˆ˜ì§‘ ì™„ë£Œ")
        logger.info(f"   ğŸ“Š ëˆ„ì  ì´ê³„: {len(all_videos)}ê°œ")
        logger.info(f"      - ìë§‰ ìˆìŒ: {transcript_success}ê°œ")
        logger.info(f"      - ìë§‰ ì—†ìŒ: {transcript_failed}ê°œ")
        
        # API ë¶€í•˜ ë°©ì§€
        time.sleep(0.5)
    
    # ===========================
    # CSV ì €ì¥
    # ===========================
    
    if not all_videos:
        logger.warning("\nâš ï¸  ìˆ˜ì§‘ëœ ì˜ìƒì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    logger.info(f"\n{'='*70}")
    logger.info("ğŸ’¾ CSV ì €ì¥ ì¤‘...")
    
    df = pd.DataFrame(all_videos)
    
    # ì»¬ëŸ¼ ìˆœì„œ ì •ë ¬
    column_order = [
        'platform', 'video_id', 'url',
        'channel_id', 'channel_name',
        'title', 'description', 'published_datetime',
        'duration', 'view_count', 'like_count', 'comment_count',
        'category_id', 'tags', 'hashtags',
        'sponsor_phone', 'sponsor_partner_id',
        'thumbnail_url',
        'youtube_transcript', 'transcript_language', 'transcript_status', 'has_transcript',
        'collected_date'
    ]
    
    df = df[column_order]
    
    # íŒŒì¼ëª… ìƒì„±
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    output_file = f'youtube/youtube_pm_v2_{timestamp}.csv'
    
    df.to_csv(output_file, index=False, encoding='utf-8-sig')
    
    elapsed_time = time.time() - start_time
    
    # ===========================
    # ê²°ê³¼ ì¶œë ¥
    # ===========================
    
    logger.info(f"{'='*70}")
    logger.info("âœ… ìˆ˜ì§‘ ì™„ë£Œ!")
    logger.info(f"{'='*70}")
    logger.info(f"\nğŸ“Š ìˆ˜ì§‘ ê²°ê³¼:")
    logger.info(f"  - ì´ ì˜ìƒ ìˆ˜: {len(df)}ê°œ")
    logger.info(f"  - ì¶”ì²œì¸ ì „í™”ë²ˆí˜¸: {df['sponsor_phone'].notna().sum()}ê°œ ({df['sponsor_phone'].notna().sum()/len(df)*100:.1f}%)")
    logger.info(f"  - íŒŒíŠ¸ë„ˆ ID: {df['sponsor_partner_id'].notna().sum()}ê°œ ({df['sponsor_partner_id'].notna().sum()/len(df)*100:.1f}%)")
    logger.info(f"  - ìë§‰ ìˆìŒ: {df['has_transcript'].sum()}ê°œ ({df['has_transcript'].sum()/len(df)*100:.1f}%)")
    logger.info(f"  - ìë§‰ ì—†ìŒ (Whisper í•„ìš”): {(~df['has_transcript']).sum()}ê°œ")
    
    logger.info(f"\nğŸ“ˆ í†µê³„:")
    logger.info(f"  - í‰ê·  ì¡°íšŒìˆ˜: {df['view_count'].mean():.0f}")
    logger.info(f"  - í‰ê·  ì¢‹ì•„ìš”: {df['like_count'].mean():.0f}")
    logger.info(f"  - í‰ê·  ëŒ“ê¸€: {df['comment_count'].mean():.0f}")
    logger.info(f"  - í‰ê·  ìë§‰ ê¸¸ì´: {df['youtube_transcript'].str.len().mean():.0f}ì")
    
    logger.info(f"\nâ±ï¸  ì†Œìš” ì‹œê°„: {elapsed_time:.1f}ì´ˆ ({elapsed_time/60:.1f}ë¶„)")
    logger.info(f"  - í‰ê·  ì†ë„: {elapsed_time/len(df):.2f}ì´ˆ/ì˜ìƒ")
    
    logger.info(f"\nğŸ“ ì €ì¥ ìœ„ì¹˜: {output_file}")
    
    # ìë§‰ ì—†ëŠ” ì˜ìƒ ëª©ë¡ ì €ì¥
    no_transcript_df = df[~df['has_transcript']][['video_id', 'url', 'title', 'transcript_status']]
    if len(no_transcript_df) > 0:
        no_transcript_file = f'youtube/youtube_no_transcript_{timestamp}.csv'
        no_transcript_df.to_csv(no_transcript_file, index=False, encoding='utf-8-sig')
        logger.info(f"\nğŸ“‹ ìë§‰ ì—†ëŠ” ì˜ìƒ ëª©ë¡: {no_transcript_file}")
        logger.info(f"   â†’ Google Colab Whisperë¡œ ì²˜ë¦¬ í•„ìš”")
    
    # ìƒìœ„ 5ê°œ ì˜ìƒ ë¯¸ë¦¬ë³´ê¸°
    logger.info(f"\n{'='*70}")
    logger.info("ğŸ“º ìƒìœ„ 5ê°œ ì˜ìƒ ë¯¸ë¦¬ë³´ê¸°:")
    logger.info(f"{'='*70}")
    
    for idx, row in df.head(5).iterrows():
        logger.info(f"\n{idx+1}. {row['title'][:60]}...")
        logger.info(f"   ì±„ë„: {row['channel_name']}")
        logger.info(f"   ì¡°íšŒìˆ˜: {row['view_count']:,} | ì¢‹ì•„ìš”: {row['like_count']:,}")
        logger.info(f"   ìë§‰: {'âœ… ìˆìŒ' if row['has_transcript'] else 'âŒ ì—†ìŒ'}")
        if row['has_transcript']:
            logger.info(f"   ìë§‰ ë¯¸ë¦¬ë³´ê¸°: {row['youtube_transcript'][:100]}...")
        if row['sponsor_phone']:
            logger.info(f"   ğŸ“ ì¶”ì²œì¸: {row['sponsor_phone']}")
    
    logger.info(f"\n{'='*70}")
    logger.info("ğŸ‰ v2.0 ìˆ˜ì§‘ ì™„ë£Œ!")
    logger.info(f"{'='*70}")
    logger.info(f"\në‹¤ìŒ ë‹¨ê³„:")
    logger.info(f"  1. {output_file} íŒŒì¼ í™•ì¸")
    logger.info(f"  2. ìë§‰ ì—†ëŠ” ì˜ìƒ â†’ Google Colab Whisper ì²˜ë¦¬")
    logger.info(f"  3. ì¸ë„¤ì¼ OCR â†’ Google Colab Vision API")
    logger.info(f"  4. ê²°ê³¼ ë³‘í•© â†’ ë„¤ì´ë²„ ë¸”ë¡œê·¸ì™€ í†µí•© ë¶„ì„")

if __name__ == "__main__":
    main()
